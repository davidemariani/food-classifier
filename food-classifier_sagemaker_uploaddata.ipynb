{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "The dataset is retrieved from the website http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz using as a reference the following research paper\n",
    "\n",
    "\n",
    "> Lukas Bossard, Matthieu Guillaumin, Luc Van Gool - Food-101 – Mining Discriminative Components with Random Forests\n",
    "\n",
    "The Food-101 data set consists of images from Foodspotting [1]. Any use beyond\n",
    "   scientific fair use must be negociated with the respective picture owners\n",
    "   according to the Foodspotting terms of use [2].\n",
    "\n",
    "[1] http://www.foodspotting.com/\n",
    "[2] http://www.foodspotting.com/terms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing essential modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import path\n",
    "import time\n",
    "from random import seed, choice\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the data folder in case a cleaning is required\n",
    "#shutil.rmtree(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-07 08:30:11--  http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz [following]\n",
      "--2020-03-07 08:30:12--  https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4996278331 (4.7G) [application/x-gzip]\n",
      "Saving to: ‘../data/food-101.tar.gz’\n",
      "\n",
      "../data/food-101.ta 100%[===================>]   4.65G  39.2MB/s    in 2m 0s   \n",
      "\n",
      "2020-03-07 08:32:12 (39.6 MB/s) - ‘../data/food-101.tar.gz’ saved [4996278331/4996278331]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the data will be downloaded and automatically extracted to the data folder ../data/food-101/images\n",
    "%mkdir ../data\n",
    "!wget -O ../data/food-101.tar.gz http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "!tar -zxf ../data/food-101.tar.gz -C ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organise train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing into train and test set using the json metadata \n",
    "\n",
    "metafolder = \"../data/food-101/meta/\"\n",
    "train_meta = pd.read_json(path_or_buf = metafolder + \"train.json\")\n",
    "test_meta = pd.read_json(path_or_buf = metafolder + \"test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Organising metdatada for training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected categories : ramen, carrot_cake, beef_carpaccio, strawberry_shortcake, escargots\n"
     ]
    }
   ],
   "source": [
    "#organising metadata for training, testing and validation\n",
    "validation_split = 0.2\n",
    "val_split_idx = int(np.floor(train_meta.shape[0]*validation_split))\n",
    "\n",
    "#folder with all the food images\n",
    "data_dir = \"../data/food-101/images/\"\n",
    "folders_sorted = sorted(os.listdir(data_dir))\n",
    "\n",
    "#number of categories to randomly select\n",
    "nc = 5\n",
    "\n",
    "#selecting a randomn subset of categories\n",
    "seed(42)\n",
    "\n",
    "selection = []\n",
    "while len(selection) < nc:\n",
    "    pick = choice(folders_sorted)\n",
    "    if pick not in set(selection):\n",
    "        selection.append(pick)\n",
    "        \n",
    "print(\"Selected categories : {}\".format(', '.join(map(str, selection))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 images used for training\n",
      "750 images used for validation\n",
      "1250 images used for testing\n"
     ]
    }
   ],
   "source": [
    "#create folder with data to upload to s3\n",
    "%mkdir ../data/s3_train_test_data\n",
    "%mkdir ../data/s3_train_test_data/train_img \n",
    "%mkdir ../data/s3_train_test_data/valid_img\n",
    "%mkdir ../data/s3_train_test_data/test_img\n",
    "\n",
    "train_meta = train_meta[selection].iloc[:train_meta.shape[0] - val_split_idx]\n",
    "\n",
    "valid_meta = train_meta[selection].iloc[train_meta.shape[0] - val_split_idx:]\n",
    "\n",
    "test_meta = test_meta[selection]\n",
    "\n",
    "#Setting train, validation and test set target folder\n",
    "#target folder - train\n",
    "trainfolder = \"../data/s3_train_test_data/train_img/\"\n",
    "\n",
    "#target folder - validation\n",
    "validfolder = \"../data/s3_train_test_data/valid_img/\"\n",
    "\n",
    "#target folder -test\n",
    "testfolder = \"../data/s3_train_test_data/test_img/\"\n",
    "\n",
    "print(\"{} images used for training\".format(train_meta.shape[0]*train_meta.shape[1]))\n",
    "print(\"{} images used for validation\".format(valid_meta.shape[0]*valid_meta.shape[1]))\n",
    "print(\"{} images used for testing\".format(test_meta.shape[0]*test_meta.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing into train and test set using the json metadata \n",
    "\n",
    "def organise_files_from_df(df, datafolder, datatarget):\n",
    "    \"\"\"\n",
    "    This function moves files contained in a folder (datafolder) to a target path (datatarget),\n",
    "    based on the information contained on a dataframe (df) where each column corresponds to a \n",
    "    class name (sub-folder). Every column of the dataset contains a list of filenames to be moved.\n",
    "    \"\"\"\n",
    "    \n",
    "    #creating target folder\n",
    "    if not path.exists(datatarget):\n",
    "        os.mkdir(datatarget)\n",
    "    \n",
    "    #iterating through dataframe columns ( =  labels)\n",
    "    for label in list(df.columns):\n",
    "        \n",
    "        #create folder\n",
    "        foldername = datatarget + str(label)\n",
    "        \n",
    "        if not path.exists(foldername):\n",
    "            os.mkdir(foldername)\n",
    "        \n",
    "        #move each file\n",
    "        for file in list(df[label]):\n",
    "            \n",
    "            fileoriginal =  datafolder + file + \".jpg\"\n",
    "            filetarget = datatarget +\"/\" + file + \".jpg\"\n",
    "            \n",
    "            try:\n",
    "                if not path.exists(filetarget):\n",
    "                    shutil.copyfile(fileoriginal, filetarget)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(\"File {} not found!\".format(file))\n",
    "                pass\n",
    "\n",
    "#origin folder\n",
    "imagefolder = \"../data/food-101/images/\"\n",
    "\n",
    "\n",
    "organise_files_from_df(train_meta, imagefolder, trainfolder)\n",
    "\n",
    "organise_files_from_df(valid_meta, imagefolder, validfolder)\n",
    "\n",
    "organise_files_from_df(test_meta, imagefolder, testfolder)\n",
    "\n",
    "#to delete the origin folder, uncomment the line below\n",
    "#shutil.rmtree(imagefolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to S3\n",
    "\n",
    ">The below cells load in some AWS SageMaker libraries, starts a SageMaker session and creates a default bucket. After creating this bucket, it upload the locally stored data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Upload training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to s3 after 361.97146677970886 seconds\n"
     ]
    }
   ],
   "source": [
    "prefix = \"food-classifier\"\n",
    "datafolder = \"../data/s3_train_test_data\"\n",
    "# upload all data to S3\n",
    "\n",
    "#this is slow!\n",
    "start = time.time()\n",
    "input_data = sagemaker_session.upload_data(path=datafolder, bucket=bucket, key_prefix=prefix)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Data uploaded to s3 after {} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good!\n"
     ]
    }
   ],
   "source": [
    "# check that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    #print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('All good!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
